{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 1\n",
    "\n",
    "#### 1. What is the difference between a normal distribution and standard normal distribution?\n",
    "\n",
    "A standard normal distribution is a normal distribution with the mean equal to 0 and the standard deviation equal to 1.\n",
    "\n",
    "#### 2. Go through the documentation on uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules / libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create the drawing space\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# Compute the mean, variance, skew, and kurtosis for the standard uniform distribution:\n",
    "mean, var, skew, kurt = uniform.stats(moments='mvsk')\n",
    "\n",
    "# PPF = Percent Point Function - i.e. percentile\n",
    "# np.linspace is used to \"return evenly spaced numbers over a specified interval\".\n",
    "\n",
    "# Combining ppf with linspace gets the x-axis numbers. For the standard uniform\n",
    "# distribution, using x = np.linspace(0.01, 0.99, 100) leads to similar results.\n",
    "x = np.linspace(uniform.ppf(0.01), uniform.ppf(0.99), 100)\n",
    "\n",
    "# PDF = Probability Density Function. This generates random values that fit the\n",
    "# uniform standard distribution for the values in x\n",
    "\n",
    "# ax.plot keywords: lw = linewidth, alpha = transparency\n",
    "\n",
    "# We're going to plot the probability density function\n",
    "ax.plot(x, uniform.pdf(x), 'r-', lw=5, alpha=0.6, label='uniform pdf')\n",
    "\n",
    "# Freeze the distribution and display the frozen pdf:\n",
    "rv = uniform()\n",
    "ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
    "\n",
    "# np.allclose \"returns True if two arrays are element-wise equal within a tolerance.\"\n",
    "# CDF = Cumulative Distribution Function\n",
    "\n",
    "# \"Check accuracy of cdf and ppf:\"\n",
    "vals = uniform.ppf([0.001, 0.5, 0.999])\n",
    "print(np.allclose([0.001, 0.5, 0.999], uniform.cdf(vals)))\n",
    "\n",
    "# RVS = Random VariateS\n",
    "r = uniform.rvs(size=1000)\n",
    "\n",
    "# Plot the distribution\n",
    "ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Discuss the use of uniform distribution in generating random numbers.\n",
    "\n",
    "TBA\n",
    "\n",
    "#### 4. Plot a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = np.random.randn(1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 12))\n",
    "plt.hist(distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acitivity 2\n",
    "\n",
    "#### 1. What kind of problems we can solve with supervised learning? List down some examples with the factors and the target.\n",
    "\n",
    "\n",
    "> Supervised learning problems, where an output attribute is present in the dataset and the target of the analysis is to derive a model that describes the relationship between this output attribute and other input attributes in the dataset.\n",
    "\n",
    "There are 2 different types of supervised learning: *regression* & *classification*.\n",
    "\n",
    "Regression problems examples:  \n",
    "\n",
    "* Finding the highest margin donors / customers from a non-profit / business database  \n",
    "    * *Factors:* gender, state, income, political view \n",
    "    * *Target:* total donation / total profit\n",
    "- Forecasting future stock prices (or temperatures, revenue):\n",
    "    - *Factors:* political events, press releases, selling / buying of stocks in the previous months\n",
    "    - *Target:* stock price\n",
    "\n",
    "*Algorithms:* linear regression, logistic regression and polynomial regression\n",
    "\n",
    "Classification problems examples:\n",
    "* Classify spam email from non-spam email\n",
    "    * *Factors:* email addresses, subject lines, number of typos in the email body, key phrases in the email (e.g. requests for credit card details), the presence of non-regular attachments (e.g. *.exe*, *.apk* files)\n",
    "    * *Target:* finding spam email\n",
    "- Finding out what customers would buy based on a previous profile\n",
    "    - *Factors:* delivery address, other visited websites, other products they viewed, total basket amount, previously bought items, average price of products\n",
    "    - *Target:* creating \"customer types\" (to later target advertisement to)\n",
    "* Whether car sales will increase, decrease or remain stable (3 possible outcomes) over the next 12 months.\n",
    "    * *Factors:* number of cars sold in the past months, car prices, \n",
    "    * *Target:* car sales trend\n",
    "\n",
    "*Algorithms:* linear classifiers, support vector machines, decision trees, random forest\n",
    "\n",
    "#### 2. What kind of problems we can solve with unsupervised learning? List down some examples with the factors and the target.\n",
    "\n",
    "Unsupervised learning allows machines to discover hidden patterns in data, which helps in *clustering*, *association*, and *dimensionality reduction* problems. The goal of unsupervised learning is to offer undiscovered insights about data.\n",
    "\n",
    "Clustering problems examples:  \n",
    "\n",
    "* Market segmentation\n",
    "* Image compression\n",
    "* News sections\n",
    "\n",
    "*Algorithms:* exclusive (K-means clustering), overlapping (fuzzy K-means clustering), hierarchical (Ward's, average, minimum, and maximum linkage), and probabilistic (Gaussian mixture models).\n",
    "\n",
    "Association problems examples:  \n",
    "\n",
    "* Market basket analysis\n",
    "* Recommendation engines, e.g. Spotify, Amazon\n",
    "\n",
    "*Algorithms:* Apriori, Eclat, FP-Growth\n",
    "\n",
    "Dimensionality reduction problems examples:  \n",
    "\n",
    "* Reduce the nunmber of features in a dataset (to prevent data overfitting, improve data\n",
    "visualization)\n",
    "* Removing noise from a picture to improve quality\n",
    "* Anomaly detection \n",
    "\n",
    "*Algorithms:* principal component analysis, singular value decomposition, autoencoders (which leverage neural networks)\n",
    "\n",
    "### Activity 3\n",
    "\n",
    "#### Read the article medium article. List down some of the keywords that you identified in the article. Do not worry about understanding what do the terms mean right now. We will discuss linear regression in greater detail as we go on.\n",
    "\n",
    "The linear regression model is used to fit a slope to the target data given a number of features. In order to calculate the gradient and intercept of the slope, the algorithm calculates the mean squared error of the slope and iterates until it reaches the minimum possible MSE for the given features and target data.\n",
    "\n",
    "### Activity 4\n",
    "\n",
    "#### Display the OLS summary using Statmodels library and conduct your research to find out the different statistics in the table. What does each element in the table mean? (There is a summary table in the output when you use linear regression with Statmodels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with random numbers for simple linear regression model\n",
    "df = pd.DataFrame(100 * np.random.rand(1000, 2), columns=['feature', 'target'])\n",
    "\n",
    "# X-y split\n",
    "X = df['feature']\n",
    "y = df['target']\n",
    "\n",
    "# Fit the data\n",
    "X = sm.add_constant(X)      # Adds a column of ones to the array because no constant is added by \n",
    "                            # default in the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see in the OLS summary and what it means:\n",
    "- **Df Residuals:** sample size (no. of observations) - (number of variables + 1)\n",
    "> Degree of freedom (Df) is the number of independent observations on the basis of which the sum of squares is calculated.\n",
    "- **R-squared:** \n",
    "> The coefficient of determination that tells us that how much percentage variation independent variable can be explained by independent variable, e.g. 66.9 % variation in y can be explained by X. \n",
    "In this case, 0% of the variation in y can be explained by X.\n",
    "- **F-statistic:**\n",
    "> F test tells the goodness of fit of a regression. The test is similar to the t-test or other tests we do for the hypothesis. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
